{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Yolov5 Pedestrians and Crosswalks detection**\n",
        "</div>\n",
        "This notebook is used to detect pedestrians, crosswalks and whether it's safe for cars to cross the crosswalk using green bounding boxes or unsafe to cross using red bounding boxes.\n",
        "Yolov5 weights is used for detection of pedestrians \n",
        "Training on custom dataset obtained using roboflow tool to detect crosswalks\n",
        "Yolov5 custom weights (best.pt) weights is used for detection of crosswalks\n",
        "\n",
        "---\n",
        "\n",
        "TensorBoard tool is used for providing the measurements and visualizations needed during the training workflow for tracking experiment metrics like loss and accuracy and precision/recall graphs.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- 20 images and labels for training\n",
        "- 9 images and labels for validation  \n",
        "- 100 images for testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## **Preparing the notebook**\n",
        "</div>\n",
        "\n",
        "*  mounting drive\n",
        "*  clone yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJr_9dXGpJ05",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "location = \"/content/drive/MyDrive/crosswalk_\" # --> location of test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gE-Ez1qtyIA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## Training crosswalk Data\n",
        "</div>\n",
        "\n",
        "Crosswalk folder:\n",
        "\n",
        "*   train \n",
        "     1.   images\n",
        "     2.   labels\n",
        "*   valid\n",
        "     1.   images\n",
        "     2.   labels\n",
        "\n",
        "*   data.yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4HZx7Gndbrh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 100 --data {location}/data.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuxHmxllTwN"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## Tensorboard\n",
        "</div>\n",
        "\n",
        "TensorBoard tool is used for providing the measurements and visualizations needed during the training workflow for tracking experiment metrics like loss and accuracy and precision/recall graphs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erxHu7x7rSt5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "\n",
        "## Objection detection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dganpatgr6EW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, etc.\n",
        "model2 = torch.hub.load('ultralytics/yolov5', 'custom', '/content/yolov5/runs/train/exp/weights/best.pt')  # custom trained model\n",
        "\n",
        "model.conf = 0.5\n",
        "model.classes = 0\n",
        "images = '/content/drive/MyDrive/images/' # --> your test data\n",
        "images = glob.glob(images + '/*.png')\n",
        "boxes_pedestrian = []\n",
        "boxes_crosswalk = []\n",
        "for im in images:\n",
        "  \n",
        "  # Inference\n",
        "  results1 = model(im)\n",
        "  results2 = model2(im)\n",
        "\n",
        "  boxes_pedestrian.append(list(results1.xyxy[0])) # ---> pedestrian bounding boxes for all images \n",
        "  boxes_crosswalk.append(list(results2.xyxy[0])) # ---> crosswalk bounding boxes for all images \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOtVcz5QsKMT",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "%cd '/content/'\n",
        "!mkdir output2\n",
        "output = '/content/output2/' \n",
        "def dims(x):\n",
        "\n",
        "    a = np.array([float(x[0]),float(x[1]),float(x[2]),float(x[3]),float(x[4])])\n",
        "        \n",
        "    x,y,w,h = a[0],a[1],a[2],a[3] \n",
        "    \n",
        "    left = int(x) \n",
        "    top = int(y) \n",
        "    right = int(w)\n",
        "    bottom = int(h) \n",
        "    conf = a[4]\n",
        "    return left,top,right,bottom,conf\n",
        "\n",
        "def draw_bounding_boxes(boxes_pedestrian,boxes_crosswalk,images):\n",
        "\n",
        "  img_num = 0\n",
        "  thickness = 3\n",
        "  for box_pedestrian,box_crosswalk in zip(boxes_pedestrian,boxes_crosswalk):\n",
        "\n",
        "    box_pedestrian = list(box_pedestrian)\n",
        "    box_crosswalk = list(box_crosswalk)\n",
        "\n",
        "    img_path = images[img_num]\n",
        "    image = cv.imread(img_path)\n",
        "    save_path = output\n",
        "    dh, dw, _ = image.shape\n",
        "    overlapped_c_p = []\n",
        "    \n",
        "    i = 0\n",
        "    for p in box_pedestrian:\n",
        "      while box_crosswalk:\n",
        "        c = box_crosswalk[i]\n",
        "        if ((min(p[2],c[2])>max(p[0],c[0])) & (min(p[3],c[3])>max(p[1],c[1]))):\n",
        "          overlapped_c_p.append(np.array(c))\n",
        "          box_crosswalk.remove(c)\n",
        "          i = 0\n",
        "        else:\n",
        "          i = i+1\n",
        "          \n",
        "    for c in box_crosswalk:\n",
        "\n",
        "      left_c,top_c,right_c,bottom_c,conf_c = dims(c)\n",
        "      #green\n",
        "      cv.rectangle(image, (left_c,top_c), (right_c, bottom_c ), (0, 128, 0), thickness)\n",
        "      cv.putText(image, 'crosswalk safe '+ \"%.3f\" % conf_c, (left_c, top_c), cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,255,255), thickness)\n",
        "    for ov in overlapped_c_p:\n",
        "\n",
        "      left_c,top_c,right_c,bottom_c,conf_c = dims(ov)\n",
        "      #red\n",
        "      cv.rectangle(image, (left_c,top_c), (right_c, bottom_c ), (0, 0, 255), thickness)\n",
        "      cv.putText(image, 'crosswalk unsafe ' + \"%.3f\" % conf_c, (left_c, top_c), cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,255,255), thickness)\n",
        "    \n",
        "\n",
        "    for p in box_pedestrian:\n",
        "    \n",
        "      left_p,top_p,right_p,bottom_p,conf_p = dims(p)\n",
        "    \n",
        "      cv.rectangle(image, (left_p,top_p), (right_p, bottom_p), (255, 0, 0), thickness)\n",
        "      cv.putText(image, 'pedestrian'+ \"%.3f\" % conf_p, (left_p, top_p), cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,255,255), thickness)\n",
        "    \n",
        "    cv.imwrite(os. path. join(output , \"image_{}.jpg\".format(img_num)), image)  # Save image localy \n",
        "    img_num+=1\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuKxu5pbsr34",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "draw_bounding_boxes(boxes_pedestrian,boxes_crosswalk,images)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
